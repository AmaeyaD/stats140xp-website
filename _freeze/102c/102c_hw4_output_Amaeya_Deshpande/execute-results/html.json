{
  "hash": "e594972248656e83a7f2d529ef4786d0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Stats 102C, Homework 4 - Intro to MCMC\"\nauthor: \"Amaeya Deshpande\"\noutput:\n  pdf_document: default\n  html_document: default\n---\n\n\n\n\n\nHomework Questions, copyright Miles Chen. Do not post or distribute without permission.\n\n**Do not post your solutions online on a site like github. Violations will be reported to the Dean of Students.**\n\nModify this file with your answers and responses.\n\n## Academic Integrity Statement\n\nBy including this statement, I, Amaeya Deshpande, declare that all of the work in this assignment is my own original work. At no time did I look at the code of other students nor did I search for code solutions online. I understand that plagiarism on any single part of this assignment will result in a 0 for the entire assignment and that I will be referred to the dean of students.\n\n# Reading:\n\nReading is important!\n\nDoing Bayesian Data Analysis Textbook is available at: <https://www.sciencedirect.com/science/book/9780124058880>\n\n-   Read chapter 7 of Doing Bayesian Data Analysis\n-   <http://setosa.io/ev/markov-chains/>\n-   <http://setosa.io/ev/eigenvectors-and-eigenvalues/> Especially the section on steady states (stationary distributions)\n\n## Problem 1 - Transition Matrix and Stationary Distribution (Two state case)\n\nImagine a two-state Markov chain. With state 1 representing CA and state 2 representing TX.\n\nLet's pretend that each year, 9% of Californians move to TX and that 12% of Texans move to CA.\n\nCreate and display a 2x2 transition matrix $\\mathbb{P}$ in R to represent the transition probabilities.\n\nUsing algebra, find the stationary distribution $\\boldsymbol{\\pi}$, so that $\\boldsymbol{\\pi}\\mathbb{P} = \\boldsymbol{\\pi}$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nP <- rbind(c(0.91, 0.09), c(0.12, 0.88))\nw <- c(4/7, 3/7)\n```\n:::\n\n\n\nWe can use algebra to find the stationary distribution by creating a system of equations:\n\n0.91w1 + 0.12w2 = w1 0.09w1 + 0.88w2 = w2 -\\> 0.09w1 = 0.12w2 -\\> w2 = 0.75w1\n\nWe also know that w1 + w2 = 1 so...\n\n0.91w1 + 0.12(0.75w1) + 0.09w1 + 0.88(0.75w1) = 1 -\\> 1.75w1 = 1\n\nWhen we divide, we get w1 = 4/7 so knowing that w1 + w2 = 1, we get that w2 = 3/7\n\nFind the left eigenvector of $\\mathbb{P}$ and normalize it (so it sums to 1). Does it match the stationary distribution you found?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neig_vectors <- eigen(t(P))$vectors\nstationary <- t(eig_vectors[,1])\nstationary / (sum(stationary))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          [,1]      [,2]\n[1,] 0.5714286 0.4285714\n```\n\n\n:::\n:::\n\n\n\nYes, this matches the stationary distribution found using algebra.\n\n## Problem 2 - Transition Matrix and Stationary Distribution (island example)\n\nLook at the example with the politician visiting the island chain in chapter 7 of the textbook, Doing Bayesian Data Analysis. Also see Lecture 5-3.\n\nImagine another chain of 7 islands where the target distribution is equal to the probabilities of a binomial distribution with n = 6 and p = 0.6.\n\nThis 'nation' has 7 islands in a chain numbered from 0 to 6. Island 0 has prob = $\\binom{6}{0}(.6)^0(.4)^6$ = `dbinom(0, 6, 0.6)`, Island 1 has prob = $\\binom{6}{1}(.6)^1(.4)^5$ = `dbinom(1, 6, 0.6)`, Island 6 has prob = `dbinom(6, 6, 0.6)`, etc.\n\nUse the same algorithm as the politician to figure out the transition probabilities. Create and print out the full 7 x 7 transition matrix $\\mathbb{P}$. Populate the matrix with actual decimal values, and not symbols (round to 4 decimal places for display purposes).\n\nStart with the initial distribution: $\\boldsymbol{\\pi}^{(1)}$ = c(0, 0, 0, 1, 0, 0, 0)\n\nMultiply $\\boldsymbol{\\pi}^{(n)}$ by $\\mathbb{P}$ 6 times and print the results after each iteration. (Print the distribution of $\\boldsymbol{\\pi}^{(2)}$, $\\boldsymbol{\\pi}^{(3)}$, ... $\\boldsymbol{\\pi}^{(7)}$)\n\nFind the stationary distribution of the chain by finding the left eigenvector of the transition matrix and normalizing it. Check (using `all.equal()`) to see if it is equal to the target distribution (a binomial distribution with $n = 6$ and $p = 0.6$)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget <- dbinom(0:6, 6, 0.6)\nP <- matrix(rep(0, 49), nrow = 7)\nfor (i in 1:7) {\n  if (i < 7) {\n    if (target[i] < target[i + 1]) {\n      P[i, i + 1] <- 0.5\n    }\n    else {\n      P[i, i + 1] <- 0.5 * (target[i + 1] / target[i])\n    }\n  }\n  if (i > 1) {\n    if (target[i] < target[i - 1]) {\n      P[i, i - 1] <- 0.5\n    }\n    else {\n      P[i, i - 1] <- 0.5 * (target[i - 1] / target[i])\n    }\n  }\n  P[i, i] <- 1 - sum(P[i,])\n}\nround(P, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       [,1]   [,2]   [,3]   [,4]   [,5]  [,6]  [,7]\n[1,] 0.5000 0.5000 0.0000 0.0000 0.0000 0.000 0.000\n[2,] 0.0556 0.4444 0.5000 0.0000 0.0000 0.000 0.000\n[3,] 0.0000 0.1333 0.3667 0.5000 0.0000 0.000 0.000\n[4,] 0.0000 0.0000 0.2500 0.2500 0.5000 0.000 0.000\n[5,] 0.0000 0.0000 0.0000 0.4444 0.2556 0.300 0.000\n[6,] 0.0000 0.0000 0.0000 0.0000 0.5000 0.375 0.125\n[7,] 0.0000 0.0000 0.0000 0.0000 0.0000 0.500 0.500\n```\n\n\n:::\n\n```{.r .cell-code}\npi_1 = c(0, 0, 0, 1, 0, 0, 0)\npi_curr <- pi_1\nfor (i in 2:7) {\n  pi_next <- pi_curr %*% P\n  print(round(pi_next, 4))\n  pi_curr <- pi_next\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    0    0 0.25 0.25  0.5    0    0\n     [,1]   [,2]   [,3]   [,4]   [,5] [,6] [,7]\n[1,]    0 0.0333 0.1542 0.4097 0.2528 0.15    0\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]\n[1,] 0.0019 0.0354 0.1756 0.2919 0.3445 0.1321 0.0187\n       [,1]   [,2]  [,3]   [,4] [,5]   [,6]   [,7]\n[1,] 0.0029 0.0401 0.155 0.3139  0.3 0.1622 0.0259\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]\n[1,] 0.0037 0.0399 0.1553 0.2893 0.3147 0.1638 0.0332\n       [,1]   [,2]   [,3]   [,4]  [,5]   [,6]   [,7]\n[1,] 0.0041 0.0403 0.1493 0.2899 0.307 0.1724 0.0371\n```\n\n\n:::\n\n```{.r .cell-code}\neig_vectors <- eigen(t(P))$vectors\nstationary <- t(eig_vectors[,1])\nstationary <- as.vector(stationary / (sum(stationary)))\nall.equal(target, stationary)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nMultiply $\\boldsymbol{\\pi}^{(1)}$ by $\\mathbb{P}$ 500 times to get $\\boldsymbol{\\pi}^{(501)}$. Show the results after the final iteration. Do NOT show the steps in between. Did the distribution converge to the stationary distribution?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npi_curr <- pi_1\npi_next <- pi_1\nfor (i in 2:500) {\n  pi_next <- pi_curr %*% P\n  pi_curr <- pi_next\n}\nprint(round(pi_next, 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       [,1]   [,2]   [,3]   [,4]  [,5]   [,6]   [,7]\n[1,] 0.0041 0.0369 0.1382 0.2765 0.311 0.1866 0.0467\n```\n\n\n:::\n:::\n\n\n\nThe distribution does converge towards the stationary distribution. The values are not identical, but they are very similar.\n\n## Problem 3 - MCMC (Metropolis Algorithm) for the island hopping\n\nWrite code to create a Markov chain using the Metropolis Algorithm for the same island nation in problem 2.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget <- function(x){ \n  ifelse(x %in% 0:6, dbinom(x, 6, 0.6), 0)\n}\npropose <- function(x) { \n  current + sample(c(1, -1), size = 1)\n}\nn <- 10^5\nresults1 <- c(0, rep(NA, n - 1))\nset.seed(1)\nfor (t in 1:(n-1)) {\n  current <- results1[t]\n  proposed <- propose(current)\n  pmove <- target(proposed) / target(current)\n  u <- runif(1)\n  if(u < pmove) {\n    results1[t + 1] <- proposed\n  } else {\n    results1[t + 1] <- current\n  }\n}\ncounts <- table(results1)\nres <- rbind(counts/n , dbinom(0:6, 6, 0.6)) \nrownames(res) <- c(\"empirical\", \"target\")\nbarplot(res, beside = TRUE, legend.text = row.names(res), \n        args.legend = list(x = 7))\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nchisq.test(counts, p = dbinom(0:6, 6, 0.6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tChi-squared test for given probabilities\n\ndata:  counts\nX-squared = 17.037, df = 6, p-value = 0.009149\n```\n\n\n:::\n:::\n\n\n\nWhile it is not strongly reflected in the barplot, the chi-squared goodness-of-fit test with p-value less than 0.05 provides evidence to say that the values produced by the Markov chain do not come from the target distribution.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults2 <- c(6, rep(NA, n - 1))\nset.seed(2)\nfor (t in 1:(n-1)) {\n  current <- results2[t]\n  proposed <- propose(current)\n  pmove <- target(proposed) / target(current)\n  u <- runif(1)\n  if(u < pmove) {\n    results2[t + 1] <- proposed\n  } else {\n    results2[t + 1] <- current\n  }\n}\ncounts <- table(results2)\nres <- rbind(counts/n , dbinom(0:6, 6, 0.6)) \nrownames(res) <- c(\"empirical\", \"target\")\nbarplot(res, beside = TRUE, legend.text = row.names(res), \n        args.legend = list(x = 7))\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nchisq.test(counts, p = dbinom(0:6, 6, 0.6))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tChi-squared test for given probabilities\n\ndata:  counts\nX-squared = 6.9061, df = 6, p-value = 0.3296\n```\n\n\n:::\n:::\n\n\n\nBased on the barplot and the chi-squared goodness-of-fit test with p-value greater than 0.05, we do not have enough evidence to say that the values produced by the Markov chain do not come from the target distribution.\n\nRun the Metropolis Algorithm to create two Markov chains, each of length 10\\^5. For the first chain, start at x = 0 and use `set.seed(1)`. For the second, start at x = 6 and use `set.seed(2)`.\n\nFor each completed chain, print out a table of the resulting relative frequencies. Make a side-by-side barchart that shows the empirical PMF of your data and the theoretic PMF according to the binomial distribution. Use a chi-squared goodness-of-fit test to see if the generated values fit the expected probabilities. Be sure to comment on the graph and results of the test.\n\n## Problem 4 - MCMC (Metropolis Algorithm) for a single continuous random variable\n\nThe logisitic distribution is a unimodal and symmetric distribution, where the CDF is a logistic curve. The shape is similar to a normal distribution, but has heavier tails (though not as heavy as a Cauchy distribution).\n\nWe will compare Rejection Sampling to the Metropolis Algorithm for producing a sample from a distribution.\n\nThe PDF is:\n\n$$f(x; \\mu, s) = \\frac{1}{s} \\frac{e^{-(\\frac{x-\\mu}{s})} }{\\left( 1 + e^{-(\\frac{x-\\mu}{s})} \\right)^2}$$\n\nLuckily, this is implemented for us in R with `dlogis()`, which you are allowed to use to calculate the probability density of a (proposed) value.\n\nWe will generate two samples drawn from a logistic distribution with mean = 0 and scale = 1.\n\n$$f(x; \\mu = 0, s=1) = \\frac{e^{-x} }{\\left( 1 + e^{-x} \\right)^2} = \\texttt{dlogis(x)}$$\n\n### Task 4A:\n\nFirst generate a sample from the logistic distribution using rejection sampling. Propose 10\\^5 values from a random uniform distribution from -20 to 20. Calculate the necessary constant M, and implement rejection sampling. If you propose 10\\^5 values, how many values do you end up accepting?\n\nPlot the theoretic CDF of the distribution. Add the empirical CDF of your accepted values to the same plot (in a different color). Use the Kolmogorov-Smirnov test to compare your generated samples to the theoretic distributions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4)\nn <- 10^5\nproposed <- runif(n, -20, 20)\nf <- function(x) { dlogis(x) }\ng <- function(x) { 1/40 }\nM <- f(0) / g(0)\nr_x <- f(proposed) / (M * g(proposed))\nu <- runif(n)\naccept <- u < r_x\naccepted_vals <- proposed[accept]\nprint(paste(\"Number of values accepted:\", length(accepted_vals)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Number of values accepted: 9999\"\n```\n\n\n:::\n\n```{.r .cell-code}\nt_cdf <- function(x) { plogis(x) }\ne_cdf <- ecdf(accepted_vals)\ncurve(t_cdf(x), from = -10, to = 10, col = \"black\", lwd = 2, \n      ylab = \"CDF\")\nlines(e_cdf, col = \"blue\")\nlegend(\"topleft\", legend = c(\"Theoretical CDF\", \"Empirical CDF\"), \n       col = c(\"black\", \"blue\"), lwd = 1)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nks.test(accepted_vals, plogis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  accepted_vals\nD = 0.0069769, p-value = 0.7151\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n### Task 4B:\n\nUse the Metropolis algorithm to generate values from the logisitic distribution.\n\nFor your proposal distribution, use a random uniform distribution that draws a random value between $X_{current} - 1$ and $X_{current} + 1$.\n\nAs a reminder, the steps of the algorithm are as follows:\n\n-   Propose a single value from the proposal distribution.\n-   Calculate the probability of moving = min(1, P(proposed)/P(current))\n-   Draw a random value to decide if you will move or not. If you move, update the current position. If you do not move, keep the current position for another iteration.\n-   Repeat.\n\nStart at the terrible location $x^{(1)} = -19$.\n\nRun the Markov Chain for 10,000 iterations. Plot the first 1000 values of the chain and eyeball where you think the chain starts has finished 'burning-in' and is now drawing values from the target distribution. Throw away those initial values.\n\nPlot a density histogram of the remaining values and add the density of the logistic distribution to the histogram.\n\nPlot the theoretic CDF of the distribution. Add the empirical CDF of your values (after removing burn-in) to the same plot. Use the Kolmogorov-Smirnov test to compare your generated samples to the theoretic distributions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(10)\ntarget <- function(x) {\n  dlogis(x)\n}\npropose <- function(x) {\n  runif(1, x - 1, x + 1)\n}\nresults <- rep(NA, 10^4)\nresults[1] <- -19 \nfor(i in 1:(10^4 - 1)){\n  current <- results[i]\n  proposed <- propose(current)\n  p_move <- min(1, target(proposed) / target(current))\n  results[i + 1] <- ifelse(runif(1) < p_move, proposed, current)\n}\nplot(results[1:1000], type = \"l\")\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nkept_vals <- results[-(1:150)]\nhist(kept_vals, probability = TRUE, breaks = 30)\ncurve(dlogis(x), add = TRUE, col = \"blue\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\nt_cdf <- function(x) { plogis(x) }\ne_cdf <- ecdf(kept_vals)\ncurve(t_cdf(x), from = -10, to = 10, col = \"black\", lwd = 2, \n      ylab = \"CDF\")\nlines(e_cdf, col = \"blue\")\nlegend(\"topleft\", legend = c(\"Theoretical CDF\", \"Empirical CDF\"), \n       col = c(\"black\", \"blue\"), lwd = 1)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n\n```{.r .cell-code}\nks.test(kept_vals, plogis)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ks.test.default(kept_vals, plogis): ties should not be present for\nthe Kolmogorov-Smirnov test\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tAsymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  kept_vals\nD = 0.008648, p-value = 0.4528\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n\n## Problem 5 - MCMC - the effect of sigma in the proposal distribution\n\nWrite code to perform 50,000 iterations of the Metropolis Algorithm for a single continuous random variable.\n\nLet the PDF of the target distribution be:\n\n$$f(x) = c \\cdot ( sin(x) + 2 )$$\n\nfor $0 \\le x \\le 3 * \\pi$, where c is some constant so that $\\int_0^{3\\pi} f(x) dx = 1$.\n\nFor your proposal distribution, use a normal distribution, centered at the current value, with a standard deviation of $\\sigma$, which we will adjust in this problem.\n\nBegin your Markov Chain at the location x = 2.\n\nKeep in mind that the probability of a value greater than $3 \\pi$ or less than 0 is 0.\n\nGather 50,000 samples using MCMC **three** different times.\n\nThe first time, use a sigma of 0.1 for the proposal distribution.\n\nThe second time, use a sigma of 2.5 for the proposal distribution.\n\nThe third time, use a sigma = 20.\n\nKeep track of whether your proposed values are accepted or rejected, and print out the acceptance ratio.\n\nFor each MCMC run, print out the acceptance ratio, create a histogram of the sampled values, and plot the first 500 values of the chain `plot(x[1:500], type = \"l\")`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(11)\nc <- 1 / integrate(function(x) {sin(x) + 2}, 0, 3 * pi)$value\nf <- function(x) {  \n  ifelse(x < 0 || x > 3 * pi, 0, c * (sin(x) + 2))\n}\nn <- 50000\nresults <- rep(NA, n)\nresults[1] <- 2\naccepted <- 0\nfor(i in 1:(10^4 - 1)){\n  current <- results[i]\n  proposed <- rnorm(1, current, 0.1)\n  p_move <- min(1, f(proposed) / f(current))\n  if (runif(1) < p_move) {\n    results[i + 1] <- proposed\n    accepted <- accepted + 1\n  }\n  else {\n    results[i + 1] <- current\n  }\n}\nprint(paste(\"Acceptance ratio is:\", accepted / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio is: 0.1965\"\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(results, probability = TRUE, breaks = 30)\ncurve(c * (sin(x) + 2), add = TRUE, col = \"blue\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(results[1:500], type = \"l\")\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\nresults <- rep(NA, n)\nresults[1] <- 2\naccepted <- 0\nfor(i in 1:(10^4 - 1)){\n  current <- results[i]\n  proposed <- rnorm(1, current, 2.5)\n  p_move <- min(1, f(proposed) / f(current))\n  if (runif(1) < p_move) {\n    results[i + 1] <- proposed\n    accepted <- accepted + 1\n  }\n  else {\n    results[i + 1] <- current\n  }\n}\nprint(paste(\"Acceptance ratio is:\", accepted / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio is: 0.12832\"\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(results, probability = TRUE, breaks = 30)\ncurve(c * (sin(x) + 2), add = TRUE, col = \"blue\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(results[1:500], type = \"l\")\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-4.png){width=672}\n:::\n\n```{.r .cell-code}\nresults <- rep(NA, n)\nresults[1] <- 2\naccepted <- 0\nfor(i in 1:(10^4 - 1)){\n  current <- results[i]\n  proposed <- rnorm(1, current, 20)\n  p_move <- min(1, f(proposed) / f(current))\n  if (runif(1) < p_move) {\n    results[i + 1] <- proposed\n    accepted <- accepted + 1\n  }\n  else {\n    results[i + 1] <- current\n  }\n}\nprint(paste(\"Acceptance ratio is:\", accepted / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio is: 0.03018\"\n```\n\n\n:::\n\n```{.r .cell-code}\nhist(results, probability = TRUE, breaks = 30)\ncurve(c * (sin(x) + 2), add = TRUE, col = \"blue\", lwd = 2)\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-5.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(results[1:500], type = \"l\")\n```\n\n::: {.cell-output-display}\n![](102c_hw4_output_Amaeya_Deshpande_files/figure-html/unnamed-chunk-9-6.png){width=672}\n:::\n:::\n",
    "supporting": [
      "102c_hw4_output_Amaeya_Deshpande_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}