{
  "hash": "fee341bf8e4681a2b596390edcd34315",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Stats 102C, Homework 5 - Multivariate MCMC\"\nauthor: \"Amaeya Deshpande\"\noutput:\n  pdf_document: default\n  html_document: default\n---\n\n\n\n\n\n\nHomework questions copyright Miles Chen. Do not post or distribute without permission.\n\n**Do not post your solutions online on a site like github. Violations will be reported to the Dean of Students.**\n\nModify this file with your answers and responses.\n\n## Academic Integrity Statement\n\nBy including this statement, I, Amaeya Deshpande, declare that all of the work in this assignment is my own original work. At no time did I look at the code of other students nor did I search for code solutions online. I understand that plagiarism on any single part of this assignment will result in a 0 for the entire assignment and that I will be referred to the dean of students.\n\n# Problem 1\n\nRead, understand, and use the deciphering R code to decode the following messages:\n\nmessage1 \\<- \"IFOECP WFWAG IVAG UMMW QX IVAGXW OMJX QX IVAGXW V UPFXAW BMYXMAX IQM IMCOW SOVH IFGQ QFY\"\n\nmessage2 \\<- \"Y CYLZ OZN JYSD ZFE SNGNJ XPHN OP HN Y CYLZ SPSN PM OZYL ZFE ZFWWNSNE LP EP FVV CZP VYGN OP LNN LBXZ OYHNL ABO OZFO YL SPO MPJ OZNH OP ENXYEN FVV CN ZFGN OP ENXYEN YL CZFO OP EP CYOZ OZN OYHN OZFO YL DYGNS OP BL\"\n\nmessage3 \\<- \"ZHR PKNYSKCT, HK YOT QMSKTY TSRYO, DSK OSA SMUSEN SNNJDTA YOSY OT USN DHRT PKYTMMPLTKY YOSK AHMQOPKN GTCSJNT OT OSA SCOPTBTA NH DJCO-YOT UOTTM, KTU EHRV, USRN SKA NH HK-UOPMNY SMM YOT AHMQOPKN OSA TBTR AHKT USN DJCV SGHJY PK YOT USYTR OSBPKL S LHHA YPDT. GJY CHKBTRNTME, YOT AHMQOPKN OSA SMUSEN GTMPTBTA YOSY YOTE UTRT ZSR DHRT PKYTMMPLTKY YOSK DSK-ZHR QRTCPNTME YOT NSDT RTSNHKN\"\n\nSome punctuation (e.g. apostrophes) have been removed from the text.\n\nYou may need to modify a few parameters in the code.\n\nOne is the starting seed. Based on where you randomly start, it is possible to get \"stuck\" in a region that delivers nonsense results.\n\nAnother is the weight used to combine the probability values, in the line of code:\n\n``` c\nweight <- 0.07 # tuneable parameter # line 157\ncur_combined_loglike <- cur_2letter_prob + weight * cur_word_prob\n```\n\nAnother is the value to return if a word does not appear in the lexicon. This value is in the function `one_gram_prob`. It is currently set to 1e-10, but can be modified to another value.\n\n``` c\none_gram_prob <- function(word, lex) {\n  row <- which(lex$word == word)\n  if (length(row) == 0) {\n    return( 1e-10 ) ## tuneable parameter # line 128\n  }\n```\n\n## Results\n\nFor each coded message, write what you believe to be the correct deciphering of the text.\n\nYou can use your `best_decode` result and the power of the Internet (these are somewhat famous quotes).\n\n### Important: Answer Prohibition\n\nDo not post the answer to this question on Campuswire. Do not ask what the answer is. The problem does not ask you to include the code here, so I cannot verify if students actually did or did not attempt the problem on their own machine. As such, do not share what the answer is to this problem. Plus, it's fun to see the code run and I want you to experience that.\n\n### Your answers:\n\n**Message 1**\n\ntrue message: WILBUR DIDNT WANT FOOD HE WANTED LOVE HE WANTED A FRIEND SOMEONE WHO WOULD PLAY WITH HIM\n\n**Message 2**\n\ntrue message: LIVE TO SEE SUCH TIMES BUT THAT IS NOT FOR THEM TO DECIDE ALL WE HAVE TO DECIDE IS WHAT TO DO WITH THE TIME THAT IS GIVEN TO US\n\n**Message 3**\n\ntrue message: FOR INSTANCE, ON THE PLANET EARTH, MAN HAD ALWAYS ASSUMED THAT HE WAS MORE INTELLIGENT THAN DOLPHINS BECAUSE HE HAD ACHIEVED SO MUCH-THE WHEEL, NEW YORK, WARS AND SO ON-WHILST ALL THE DOLPHINS HAD EVER DONE WAS MUCK ABOUT IN THE WATER HAVING A GOOD TIME. BUT CONVERSELY, THE DOLPHINS HAD ALWAYS BELIEVED THAT THEY WERE FAR MORE INTELLIGENT THAN MAN-FOR PRECISELY THE SAME REASONS\n\n# Problem 2: Acceptance ratios in higher dimensions\n\nWe will explore the effect of having higher dimensions on acceptance ratios $p_{move} = \\frac{f(\\mathbf{x}_{proposed})}{f(\\mathbf{x}_{t})}$\n\nWe will look at 3 target distributions in different dimensions.\n\n-   The first distribution will be a univariate standard normal distribution (mean 0 and sd 1).\n    -   Current location is $x_t = 4$.\n    -   The proposal distribution will be a uniform distribution with a width of 4. ($x_t \\sim \\text{Unif}[x_t \\pm 2]$)\n-   The second distribution will be a 3D normal distribution (mean (0,0,0) and sigma = Identity matrix(3)).\n    -   Current location is $\\mathbf{x}_t = (4, 4, 4)$.\n    -   The proposal distribution will be a uniform distribution with a width of 4 in all three directions. Each value can be sampled independently.\n    -   $x_{1p} \\sim \\text{Unif}[x_{1t} \\pm 2]$, $x_{2p} \\sim \\text{Unif}[x_{2t} \\pm 2]$, $x_{3p} \\sim \\text{Unif}[x_{3t} \\pm 2]$\n-   The third distribution will be a 10D normal distribution (mean rep(0, 10) and sigma = Identity matrix(10)).\n    -   Current location is $\\mathbf{x}_t = (4, \\ldots, 4)$. (4s in all 10 dimenions)\n    -   The proposal distribution will be a uniform distribution with a width of 4 in all 10 directions. ($x_{dp} \\sim \\text{Unif}[x_{dt} \\pm 2]$ for all d)\n\nBecause the distributions have diagonal covariance matrices, the joint PDF can be found using a product of univariate normal densities. There is no need to load a library like `mvtnorm`.\n\nFor each target distribution, estimate the proportion of proposed values that would be accepted if the current location is the one provided. You are not running a chain and updating the current location.\n\nEstimate the acceptance rate by running 10,000 iterations. For each iteration, propose a value, find the acceptance probability $p_{move}$ using the Metropolis algorithm, and then draw a random U to decide whether to accept or not. Keep track of the acceptances and after 10,000 iterations report the estimated acceptance rate.\n\nThere should be a pattern that the acceptance rates go down as the number of dimensions increase, though the differences in acceptance rates are likely not be orders of magnitude different.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1)\nn <- 10^4\nnormal_pdf <- function(x) {\n  prod(dnorm(x, 0, 1))\n}\n\nacceptance1D <- 0\ncurr_loc <- 4\nfor (i in 1:n) {\n  prop_loc <- curr_loc + runif(1, -2, 2)\n  prop_pdf <- normal_pdf(prop_loc)\n  curr_pdf <- normal_pdf(curr_loc)\n  p_move <- min(1, prop_pdf / curr_pdf)\n  u <- runif(1)\n  if (u < p_move) {\n    acceptance1D <- acceptance1D + 1\n  }\n}\nprint(paste(\"Acceptance ratio for 1D is:\", acceptance1D / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio for 1D is: 0.5657\"\n```\n\n\n:::\n\n```{.r .cell-code}\nacceptance3D <- 0\ncurr_loc <- rep(4, 3)\nfor (i in 1:n) {\n  prop_loc <- curr_loc + runif(3, -2, 2)\n  prop_pdf <- normal_pdf(prop_loc)\n  curr_pdf <- normal_pdf(curr_loc)\n  p_move <- min(1, prop_pdf / curr_pdf)\n  u <- runif(1)\n  if (u < p_move) {\n    acceptance3D <- acceptance3D + 1\n  }\n}\nprint(paste(\"Acceptance ratio for 3D is:\", acceptance3D / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio for 3D is: 0.4634\"\n```\n\n\n:::\n\n```{.r .cell-code}\nacceptance10D <- 0\ncurr_loc <- rep(4, 10)\nfor (i in 1:n) {\n  prop_loc <- curr_loc + runif(10, -2, 2)\n  prop_pdf <- normal_pdf(prop_loc)\n  curr_pdf <- normal_pdf(curr_loc)\n  p_move <- min(1, prop_pdf / curr_pdf)\n  u <- runif(1)\n  if (u < p_move) {\n    acceptance10D <- acceptance10D + 1\n  }\n}\nprint(paste(\"Acceptance ratio for 10D is:\", acceptance10D / n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Acceptance ratio for 10D is: 0.3591\"\n```\n\n\n:::\n:::\n\n\n\n\n# Problem 3: Multivariate Metropolis Hastings Algorithm\n\nIn the following two problems, we will compare two multivariate MCMC algorithms for sampling from a bivariate normal distribution.\n\nThe target distribution will be a bivariate normal distribution centered at (0,0) with covariance matrix `rbind(c(1, .7), c(.7, 1))`.\n\nFor the proposal distribution, use a multivariate uniform distribution centered at the current location (x1, x2), with a total span of 2. That is, sample the proposed $x_{1p}$ from $x_{1t} - 1$ to $x_{1t} + 1$, and sample $x_{2p}$ from $x_{2t} - 1$ to $x_{2t} + 1$.\n\nThe acceptance ratio $p_{move}$ is:\n\n$$p_{move} = \\frac{f(\\mathbf{x}_{proposed})}{f(\\mathbf{x}_{t})}\\frac{g(\\mathbf{x}_{t} | \\mathbf{x}_{proposed})}{g( \\mathbf{x}_{proposed}| \\mathbf{x}_{t})} = \\frac{f(x_{1p},x_{2p})}{f(x_{1t}, x_{2t})} \\frac{g(x_{1t}, x_{2t} | x_{1p},x_{2p})}{g( x_{1p},x_{2p}|x_{1t}, x_{2t})}$$\n\nBecause our proposal distribution is symmetric, $\\frac{g(x_{1t}, x_{2t} | x_{1p},x_{2p})}{g( x_{1p},x_{2p}|x_{1t}, x_{2t})} = 1$ and $p_{move}$ reduces to $\\frac{f(x_{1p},x_{2p})}{f(x_{1t}, x_{2t})}$ (and the Metropolis-Hastings algoirthm reduces to the Metropolis algorithm).\n\nWrite the code to calculate the multivariate normal density yourself (consult wikipedia <https://en.wikipedia.org/wiki/Multivariate_normal_distribution>). Do not use `mvtnorm::dmvnorm()`, as the library `mvtnorm` would make sampling from the multivariate normal trivial.\n\nStart at the arbitrary location: (10, 10)\n\nDo 1000 iterations of the Metropolis algorithm.\n\nCreate a plot of the results of your chain, and create another plot after removing the 'burn-in' values. (That is, we started in a terrible location and it took a little while for our chain to reach the 'appropriate' region. Remove those exploratory values.)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2)\nn <- 10^3\nnormal2_pdf <- function(x) {\n  cov_matrix <- rbind(c(1, .7), c(.7, 1))\n  cov_det <- det(cov_matrix)\n  maha_dist <- x %*% solve(cov_matrix) %*% x\n  exp(-0.5 * maha_dist) / sqrt((2 * pi)^2 * cov_det)\n}\nX <- matrix(NA, nrow = n, ncol = 2)\ncurr_loc <- c(10, 10)\nX[1,] <- curr_loc\nfor (i in 1:(n - 1)) {\n  prop_loc <- curr_loc + runif(2, -1, 1)\n  prop_pdf <- normal2_pdf(prop_loc)\n  curr_pdf <- normal2_pdf(curr_loc)\n  p_move <- min(1, prop_pdf / curr_pdf)\n  u <- runif(1)\n  if (u < p_move) {\n    curr_loc <- prop_loc\n  }\n  X[i + 1,] <- curr_loc\n}\nplot(X[ , 1], X[ , 2], type = 'b', pch = 19, cex = 0.2, xlab = \"X1\", ylab = \"X2\")\n```\n\n::: {.cell-output-display}\n![](102C_hw5_Amaeya_Deshpande_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(X[100:1000, 1], X[100:1000, 2], pch = 19, cex = 0.2, xlab = \"X1\", ylab = \"X2\")\n```\n\n::: {.cell-output-display}\n![](102C_hw5_Amaeya_Deshpande_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n\n\n# Problem 4: The Gibbs Sampler\n\nAgain, the target distribution will be a bivariate normal distribution centered at (0,0) with covariance matrix `rbind(c(1, .7), c(.7, 1))`.\n\nImplement a Gibbs sampler.\n\nIn each iteration, you will generate each coordinate individually using the appropriate univariate conditional distribution.\n\nFor help deriving conditioning a bivariate normal distribution, I point you to the following resource (See section A.2): <http://www.math.chalmers.se/~rootzen/highdimensional/SSP4SE-appA.pdf>\n\nYou are allowed to use the univariate `rnorm` function to generate random normal values.\n\nAgain, start at the arbitrary location: (10, 10)\n\nLet the chain run for 1000 iterations.\n\nCreate a plot of the results of your chain, and create another plot after removing the 'burn-in' values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3)\nn <- 10^3\nmu <- c(0, 0)\ncov_matrix <- rbind(c(1, .7), c(.7, 1))\nsigma1 <- sqrt(cov_matrix[1,1])\nsigma2 <- sqrt(cov_matrix[2,2])\np <- cov_matrix[1,2] / (sigma1 * sigma2)\nx1_cond <- function(x2) {\n  mu_cond <- mu[1] + (p * sigma1 * (x2 - mu[2])) / sigma2\n  sigma_cond <- (1 - p^2) * sigma1^2\n  rnorm(1, mu_cond, sigma_cond)\n}\nx2_cond <- function(x1) {\n  mu_cond <- mu[2] + (p * sigma2 * (x1 - mu[1])) / sigma1\n  sigma_cond <- (1 - p^2) * sigma2^2\n  rnorm(1, mu_cond, sigma_cond)\n}\nX <- matrix(NA, nrow = n, ncol = 2)\ncurr_loc <- c(10, 10)\nX[1,] <- curr_loc\nfor (i in 1:(n - 1)) {\n  x1 <- x1_cond(X[i, 2])\n  x2 <- x2_cond(x1)\n  X[i + 1,] <- c(x1, x2)\n}\nplot(X[4:1000, 1], X[4:1000, 2], type = 'b', pch = 19, cex = 0.2, xlab = \"X1\", ylab = \"X2\")\n```\n\n::: {.cell-output-display}\n![](102C_hw5_Amaeya_Deshpande_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "102C_hw5_Amaeya_Deshpande_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}